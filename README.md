# Nephy Bot - Offline

<img src=".\assets\info\setup_readme_imgs\noriko.png" alt="Nephy">

An offline Discord chatbot powered by local language models. **Nephy** is a playful, chaotic yet caring AI companion that engages in natural conversations with users while maintaining full privacy through local model inference.

Huge shout-out to [syntax-z](https://github.com/zeeblo), he did most of this, I simply adapted it to work with GPT4all.

---

## ğŸ¯ Overview

Nephy Bot is a Discord bot that brings intelligent conversation capabilities to your server using entirely offline, locally-hosted language models. Unlike cloud-based alternatives, all conversation processing happens on your machine, ensuring complete data privacy.

### Key Features

- ğŸ’¬ **Natural Conversations** - Engage in free-form dialogue with an AI character
- ğŸ”’ **Completely Offline** - All inference runs locally, no data sent to external servers
- ğŸ§  **Customizable Models** - Easy configuration to use different local LLM providers
- ğŸ“ **Conversation History** - Persistent chat logs stored locally in SQLite
- âš™ï¸ **User Settings** - Personalized preferences for each user
- ğŸ­ **Character Personality** - Nephy has a consistent, engaging personality
- ğŸ” **Secure** - Built-in encryption support for sensitive data
- ğŸ“Š **Modular Architecture** - Extensible cog system for easy feature additions

---

### Examples:
![pic1](./assets/info/setup_readme_imgs/convo1.png)

![pic2](./assets/info/setup_readme_imgs/convo2.png)

## ğŸ“‹ Requirements

- **Only tested with Python 3.10**
- **Local LLM Server** (e.g., GPT4All, Ollama, LM Studio, or similar)
- Dependencies listed in `requirements.txt`:
  - `discord.py` - Discord bot framework
  - `better_profanity` - Content filtering
  - `cryptography` - Data encryption
  - `requests` - HTTP client for LLM API calls


---

## ğŸš€ Quick Start

### 1. Prerequisites Setup

Before running the bot, you need a local LLM server running. Here are some options:

**Option A: Using GPT4All**
- Download from [gpt4all.io](https://www.gpt4all.io)
- Install and launch the desktop application
- The API server typically runs on `http://localhost:4891/v1/chat/completions`

### 2. Clone the Repository

```bash
git clone https://github.com/4G0NYY/Nephy-Bot-Offline
cd Nephy-Bot-Offline
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configuration

Create a `config.json` file in the project root directory:

```json
{
  "BOT_TOKEN": "your_discord_bot_token_here",
  "llm_provider": "local",
  "local": {
    "base_url": "http://localhost:4891/v1/chat/completions",
    "model": "Nous Hermes 2 Mistral DPO",
    "temperature": 0.7,
    "max_tokens": 512
  }
}
```

**Configuration Parameters:**
- `BOT_TOKEN` - Your Discord bot token from [Discord Developer Portal](https://discord.com/developers/applications)
- `base_url` - The local LLM server endpoint
- `model` - The model name installed in your LLM server
- `temperature` - Creativity level (0.0-2.0, lower = more deterministic)
- `max_tokens` - Maximum response length

### 5. Create Data Directory

Create a `data` folder in the project root:

```bash
mkdir data
```

This folder will contain the SQLite database for storing user data and conversation history.

### 6. Run the Bot

```bash
python main.py
```

The bot should now connect to Discord and be ready for interaction!

---

## ğŸ“š Project Structure

```
Nephy-Bot-Offline/
â”œâ”€â”€ main.py                    # Entry point - Bot initialization
â”œâ”€â”€ config.json                # Configuration (create this)
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ data/                      # Database directory (create this)
â”‚   â””â”€â”€ data.db               # SQLite database (auto-generated)
â”‚
â”œâ”€â”€ cogs/                      # Discord bot cogs (feature modules)
â”‚   â”œâ”€â”€ start.py              # Channel setup commands
â”‚   â”œâ”€â”€ info.py               # Help, commands, setup guides
â”‚   â””â”€â”€ misc.py               # Miscellaneous commands
â”‚
â”œâ”€â”€ utils/                     # Utility modules
â”‚   â”œâ”€â”€ chat.py               # Chat setup and message handling
â”‚   â”œâ”€â”€ nephy_ai.py           # Nephy personality & response generation
â”‚   â”œâ”€â”€ local_llm.py          # Local LLM API client
â”‚   â”œâ”€â”€ data.py               # SQLite database operations
â”‚   â”œâ”€â”€ encrypt.py            # Encryption utilities
â”‚   â””â”€â”€ views.py              # Discord UI components
â”‚
â””â”€â”€ assets/                    # Static assets
    â”œâ”€â”€ info/                 # Information files
    â”‚   â”œâ”€â”€ cmds.json         # Command descriptions
    â”‚   â”œâ”€â”€ help.json         # Help text
    â”‚   â”œâ”€â”€ settings.json     # User settings schema
    â”‚   â””â”€â”€ setup_imgs/       # Setup guide images
    â”œâ”€â”€ misc/                 # Miscellaneous data
    â”‚   â””â”€â”€ codes.json        # Status codes/messages
    â”œâ”€â”€ prompts/              # AI prompts
    â”‚   â””â”€â”€ LLM_templates.json # LLM system prompts
    â””â”€â”€ static_phrases/       # Pre-written responses
        â”œâ”€â”€ bye.json          # Goodbye messages
        â””â”€â”€ rnd_dms.json      # Random DM templates
```

---

## ğŸ”§ How It Works

### Bot Initialization (`main.py`)

1. **Configuration Loading** - Reads `config.json` for bot token and LLM settings
2. **Discord Intents** - Enables member and message content intents for full functionality
3. **Cog Loading** - Dynamically loads all modules from the `cogs/` directory
4. **Database Setup** - Creates necessary SQLite tables on first run
5. **Event Handlers** - Sets up message and ready event listeners

### Message Processing Flow

```
User sends message in DM or channel
          â†“
Bot receives message (on_message)
          â†“
Message cleaning (remove bot mentions)
          â†“
SetupChat.setup() initializes user/chat session
          â†“
Check if user exists in database
          â†“
If new user: create metadata, settings, chat records
          â†“
SetupChat.chat() calls Nephy.generate_response()
          â†“
Nephy queries local LLM via LocalLLMClient
          â†“
Response returned and sent back to Discord
```

### Conversation Generation (`utils/nephy_ai.py`)

The `Nephy` class handles AI personality and response generation:

1. **System Prompt** - Defines Nephy's personality (playful, casual, caring)
2. **Message Formatting** - Structures user input into OpenAI-compatible format
3. **LLM Query** - Sends to local LLM via HTTP POST request
4. **Response Parsing** - Extracts content from LLM JSON response
5. **Output Cleaning** - Strips whitespace and formats for Discord

Example personality:
```
"You are Nephy, a playful, slightly chaotic but caring AI companion. 
You speak casually, tease lightly, and keep responses concise. 
Stay in character and be friendly."
```

### Local LLM Client (`utils/local_llm.py`)

The `LocalLLMClient` class communicates with your local LLM server:

- Makes HTTP POST requests to the configured `base_url`
- Sends messages in OpenAI-compatible chat format
- Handles temperature and max_tokens parameters
- Parses responses from various LLM servers (GPT4All, Ollama, LM Studio, etc.)
- Includes error handling for unexpected response formats

### Database Structure (`utils/data.py`)

SQLite tables store:
- **channels** - Whitelisted Discord channels for bot operation
- **users** - User IDs
- **settings** - User preferences (model choice, DM settings, etc.)
- **chat_info** - Chat metadata (user, chat name, thread ID)
- **chat_logs** - Full conversation history (role, content)
- **private_settings** - Encrypted API tokens (if applicable)

### Modular Commands (Cogs)

**`cogs/start.py`** - Initialization
- `/add_channel` - Add channels where the bot can be used (owner only)

**`cogs/info.py`** - User Information
- `/help` - Display help information
- `/commands` - List all available commands
- `/setup` - API setup guides
- `/ai-models` - List available models

**`cogs/misc.py`** - Miscellaneous
- `/poke` - Simple test command

---

## âš™ï¸ Configuration Guide

### Changing the LLM Model

Edit `config.json` to use different models:

**For Ollama:**
```json
{
  "local": {
    "base_url": "http://localhost:11434/api/chat",
    "model": "mistral",
    "temperature": 0.7,
    "max_tokens": 512
  }
}
```

**For LM Studio:**
```json
{
  "local": {
    "base_url": "http://localhost:1234/v1/chat/completions",
    "model": "local-model",
    "temperature": 0.7,
    "max_tokens": 512
  }
}
```

### Tuning Personality

Modify the `system_prompt` in `utils/nephy_ai.py` to change Nephy's behavior:

```python
self.system_prompt = (
    "You are Nephy, a playful, slightly chaotic but caring AI companion. "
    "You speak casually, tease lightly, and keep responses concise. "
    "Stay in character and be friendly."
)
```

### Adjusting Response Quality

- **Temperature** (0.0-2.0)
  - Lower (0.0-0.5) = More focused, deterministic
  - Higher (1.5-2.0) = More creative, random
  - Default (0.7) = Balanced

- **Max Tokens** (1-4096)
  - Lower = Shorter responses, faster inference
  - Higher = Longer responses, slower inference
  - Default (512) = Reasonable balance

---

## ğŸš¦ Command Usage

### Owner-Only Commands

```
/add_channel <channel_id>
```
Whitelist a channel for bot usage.

### User Commands

```
/help              # Display help information
/commands          # List all bot commands
/setup <model>     # Show API setup guide
/ai-models         # Display available models
/poke              # Test command
```

### Regular Chat

Simply send a message in any whitelisted channel or DM the bot - Nephy will respond!

---

## ğŸ” Privacy & Security

### No Cloud Communication
- All LLM inference happens **locally** on your machine
- No conversation data is sent to external servers
- No tracking or analytics

### Data Storage
- Conversation history stored in local SQLite database
- Encrypted token storage with cryptography module (if needed)
- Full control over your data

### Content Filtering
- `better_profanity` integrated for optional content filtering
- Can be extended with custom filters

---

## ğŸ› Troubleshooting

### "Failed to connect to LLM server"
- Ensure your LLM server (GPT4All, Ollama, LM Studio) is running
- Check that `base_url` in `config.json` matches your server
- Verify firewall isn't blocking localhost connections

### "ImportError: No module named discord"
```bash
pip install discord.py
```

### Bot goes offline immediately
- Verify `BOT_TOKEN` is correct in `config.json`
- Check bot has required intents in Discord Developer Portal
- Review logs for specific error messages

### No response to messages
- Confirm the channel is whitelisted with `/add_channel`
- Check bot has message send permissions
- Verify LLM server is responding (test with curl)

### LLM returns unexpected response
- Ensure model name in config matches installed model
- Check LLM server API documentation for response format
- Increase `timeout` in `local_llm.py` if responses are slow

---

## ğŸ“ Future Enhancements

Potential features to add:
- Multi-turn conversation context preservation
- User-specific personality adjustments
- Image generation integration
- Voice chat support
- Conversation summarization
- Custom command creation
- Web dashboard for settings
- Support for multiple concurrent conversations

---

## ğŸ“„ License

See LICENSE file for details.

---

## ğŸ¤ Contributing

Found a bug or have a feature idea? Contributions are welcome! Please review CONTRIBUTIONS.md for guidelines.

---

## ğŸ“ Support

For issues, questions, or suggestions:
1. Check the Troubleshooting section above
2. Review existing GitHub issues
3. Create a new issue with detailed information about the problem

---

**Enjoy chatting with Nephy! ğŸ’¬**
